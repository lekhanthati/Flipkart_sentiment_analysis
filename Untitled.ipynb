{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21ea2106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import Memory\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "import os\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9dd88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9b205a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suresh Narayanasamy</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Certified Buyer, Chennai</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHIK P A</td>\n",
       "      <td>Over priced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Apr 2016</td>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Reviewer Name               Review Title  \\\n",
       "0            Kamal Suresh               Nice product   \n",
       "1       Flipkart Customer     Don't waste your money   \n",
       "2  A. S. Raja Srinivasan   Did not meet expectations   \n",
       "3     Suresh Narayanasamy                       Fair   \n",
       "4               ASHIK P A                Over priced   \n",
       "\n",
       "               Place of Review  Up Votes  Down Votes     Month  \\\n",
       "0   Certified Buyer, Chirakkal     889.0        64.0  Feb 2021   \n",
       "1   Certified Buyer, Hyderabad     109.0         6.0  Feb 2021   \n",
       "2  Certified Buyer, Dharmapuri      42.0         3.0  Apr 2021   \n",
       "3     Certified Buyer, Chennai      25.0         1.0       NaN   \n",
       "4                          NaN     147.0        24.0  Apr 2016   \n",
       "\n",
       "                                         Review text  Ratings  \n",
       "0  Nice product, good quality, but price is now r...        4  \n",
       "1  They didn't supplied Yonex Mavis 350. Outside ...        1  \n",
       "2  Worst product. Damaged shuttlecocks packed in ...        1  \n",
       "3  Quite O. K. , but nowadays  the quality of the...        3  \n",
       "4  Over pricedJust â?¹620 ..from retailer.I didn'...        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "323e1690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reviewer Name       10\n",
       "Review Title        10\n",
       "Place of Review     50\n",
       "Up Votes            10\n",
       "Down Votes          10\n",
       "Month              465\n",
       "Review text          8\n",
       "Ratings              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fefd93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['Review text'])\n",
    "df.reset_index(drop=True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c210ab1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8510 entries, 0 to 8509\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Reviewer Name    8508 non-null   object \n",
      " 1   Review Title     8508 non-null   object \n",
      " 2   Place of Review  8468 non-null   object \n",
      " 3   Up Votes         8508 non-null   float64\n",
      " 4   Down Votes       8508 non-null   float64\n",
      " 5   Month            8053 non-null   object \n",
      " 6   Review text      8510 non-null   object \n",
      " 7   Ratings          8510 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 532.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d4d5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(a):\n",
    "    if a>= 2.5 :\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'\n",
    "df.Ratings = df.Ratings.apply(func1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1941cb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(raw_text):\n",
    "    #removing special characters\n",
    "    temp = re.sub('[^a-zA-Z]',' ',raw_text)\n",
    "\n",
    "    temp = temp.lower()\n",
    "    \n",
    "    #tokenizing \n",
    "    tokens = temp.split()\n",
    "    \n",
    "    #removing stop words\n",
    "    tokens1 = [i for i in tokens if i not in stopwords.words('english')]\n",
    "    \n",
    "    #steming \n",
    "    stem = PorterStemmer()\n",
    "    tokens2 = [stem.stem(i) for i in tokens1]\n",
    "    \n",
    "    temp3 = ' '.join(tokens2) \n",
    "    return(temp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2a7178",
   "metadata": {},
   "source": [
    "# Identify Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acd97b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Review text']\n",
    "y = df.Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ade0a66",
   "metadata": {},
   "source": [
    "## Memoization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f97f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.apply(pre_processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc01720f",
   "metadata": {},
   "source": [
    "# Split the data into Train and Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea95c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test , y_train, y_test = split(x,y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9045e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b88e5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(a):\n",
    "    if a == 'negative':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adde3903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/saile/Desktop/Untitled%20Folder/Innomatics/Projects/Internship/Project%204/mlruns/254744688573527451', creation_time=1712492046451, experiment_id='254744688573527451', last_update_time=1712492046451, lifecycle_stage='active', name='Flipkart sentiment analysis', tags={}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment('Flipkart sentiment analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0548415e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** naive_bayes **********\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "CPU times: total: 1.17 s\n",
      "Wall time: 1.77 s\n",
      "Score on Test Data:  0.9540561827251247\n",
      "********** decision_tree **********\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "CPU times: total: 6.48 s\n",
      "Wall time: 9.51 s\n",
      "Score on Test Data:  0.9231601731601732\n",
      "********** logistic_regression **********\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "CPU times: total: 2min 20s\n",
      "Wall time: 3min 10s\n",
      "Score on Test Data:  0.9333698930627914\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# Define a memory object to cache intermediate results\n",
    "cachedir = '.cache'\n",
    "memory = Memory(location=cachedir, verbose=0)\n",
    "\n",
    "pipelines = {\n",
    "    'naive_bayes': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ], memory=memory),\n",
    "    'decision_tree': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', DecisionTreeClassifier())\n",
    "    ], memory=memory),\n",
    "    'logistic_regression': Pipeline([\n",
    "        ('vectorization', CountVectorizer()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ], memory=memory)\n",
    "}\n",
    "\n",
    "# Define parameter grid for each algorithm\n",
    "param_grids = {\n",
    "    'naive_bayes': [\n",
    "        {\n",
    "            'vectorization': [CountVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000], \n",
    "            'classifier__alpha' : [1, 10]\n",
    "        }\n",
    "    ],\n",
    "    'decision_tree': [\n",
    "        {\n",
    "            'vectorization': [CountVectorizer(), TfidfVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000],\n",
    "            'classifier__max_depth': [None, 5, 10]\n",
    "        }\n",
    "    ],\n",
    "    'logistic_regression': [\n",
    "        {\n",
    "            'vectorization': [CountVectorizer(), TfidfVectorizer()],\n",
    "            'vectorization__max_features' : [1000, 1500, 2000], \n",
    "            'classifier__C': [0.1, 1, 10], \n",
    "            'classifier__penalty': ['elasticnet'], \n",
    "            'classifier__l1_ratio': [0.4, 0.5, 0.6],\n",
    "            'classifier__solver': ['saga'],\n",
    "            'classifier__class_weight': ['balanced']\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for each algorithm\n",
    "best_models = {}\n",
    "\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=5, \n",
    "                               scoring='f1', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "    \n",
    "    %time grid_search.fit(x_train, y_train)\n",
    "    \n",
    "    best_models[algo] = grid_search.best_estimator_\n",
    "    \n",
    "    print('Score on Test Data: ',   f1_score(y_test.apply(func1),np.vectorize(func1)(grid_search.predict(x_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056a80f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b6f93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
